{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPXnwDqJOM/L73q307xx6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayur619/avc-detection/blob/notebooks/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKCMSj8aSbNc"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical,plot_model\n",
        "from tensorflow.keras.layers import Conv2D,Activation,Input,Concatenate,Flatten,Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, MeanSquaredLogarithmicError\n",
        "from tensorflow.keras.applications import MobileNetV2"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E5ancKiUDs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f90f40-f797-4d33-972f-178a51fee149"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGE9IB0aUFk6"
      },
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/AnimalVehicleCollision/data\"\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 4\n",
        "ANIMAL_LABELS_DICT = {0:\"cow\",1:\"dog\",2:\"bear\"}\n",
        "WIDTH=224\n",
        "HEIGHT=224"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nNJ5-PrUwYB"
      },
      "source": [
        "class AnimalDataGenerator:\n",
        "  def __init__(self,base_path,csv_path,batch_size):\n",
        "    self.index=0\n",
        "    self.base_path=base_path\n",
        "    self.batch_size=batch_size\n",
        "    self.df=pd.read_csv(csv_path)\n",
        "  def __load_images(self,image_name_list,label_list):\n",
        "    images=[]\n",
        "    for i,image_name in enumerate(image_name_list):\n",
        "      image=cv2.imread(os.path.join(self.base_path,ANIMAL_LABELS_DICT[label_list[i]],image_name))\n",
        "      image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "      image=cv2.resize(image,(HEIGHT,WIDTH))\n",
        "      images.append(image)\n",
        "    return np.array(images)\n",
        "  def get_steps_per_epoch(self):\n",
        "    return self.df.shape[0]//self.batch_size\n",
        "  def generate_image_batches(self,is_training):\n",
        "    while True:\n",
        "      for i in range(self.df.shape[0]//self.batch_size):\n",
        "        bounding_boxes=self.df.iloc[self.index:self.index+self.batch_size,2:6].values\n",
        "        animal_labels=self.df.iloc[self.index:self.index+self.batch_size,6].values\n",
        "        images=self.__load_images(self.df.iloc[self.index:self.index+self.batch_size,1].values,animal_labels)\n",
        "        animal_labels=to_categorical(animal_labels,num_classes=len(ANIMAL_LABELS_DICT.keys()))\n",
        "        orientation=to_categorical(self.df.iloc[self.index:self.index+self.batch_size,-1].values,num_classes=4)\n",
        "        path=self.df.iloc[self.index:self.index+self.batch_size,7:9].values\n",
        "        yield [images,bounding_boxes,animal_labels],[orientation,path]\n",
        "        self.index+=self.batch_size\n",
        "        del animal_labels,bounding_boxes,images,orientation,path\n",
        "      self.index=0"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUXMRLW3fbAb"
      },
      "source": [
        "def cnn_model():\n",
        "  input=Input(shape=(WIDTH,HEIGHT,3,),name=\"image_input\")\n",
        "  model=Conv2D(16,(3,3),padding='same')(input)\n",
        "  model=Activation('relu')(model)\n",
        "  model=Flatten()(model)\n",
        "  model=Dense(16)(model)\n",
        "  return input,model"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGYcVMmKnYDg"
      },
      "source": [
        "def cnn_mobilenetv2():\n",
        "  base_model=MobileNetV2(input_shape=(WIDTH,HEIGHT,3),weights='imagenet',include_top=False)\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "  model=GlobalAveragePooling2D()(base_model.output)\n",
        "  model=Activation('relu')(model)\n",
        "  model=Flatten()(model)\n",
        "  model=Dense(16)(model)\n",
        "  return base_model.input, model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMX3PCYugIVr"
      },
      "source": [
        "def bounding_box_model():\n",
        "  input=Input(shape=(4,),name=\"bounding_box_input\")\n",
        "  model=Dense(8)(input)\n",
        "  model=Activation('relu')(model)\n",
        "  model=Flatten()(model)\n",
        "  return input,model"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8J7m65RgbXm"
      },
      "source": [
        "def animal_label_model():\n",
        "  input=Input(shape=(len(ANIMAL_LABELS_DICT.keys()),),name=\"animal_label_input\")\n",
        "  model=Dense(8)(input)\n",
        "  model=Activation('relu')(model)\n",
        "  model=Flatten()(model)\n",
        "  return input,model"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn2dbH8WqEcG"
      },
      "source": [
        "#cnn_input,cnn_output=cnn_model()\n",
        "cnn_input,cnn_output=cnn_mobilenetv2()\n",
        "bounding_box_input,bounding_box_output=bounding_box_model()\n",
        "animal_label_input,animal_label_output=animal_label_model()\n",
        "core_model=Concatenate(axis=1)([cnn_output,bounding_box_output,animal_label_output])\n",
        "core_model=Dense(64)(core_model)\n",
        "orientation=Dense(4,activation='softmax',name='orientation_output')(core_model)\n",
        "path=Dense(2,name='path_output')(core_model)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5qeUiaXqwIA"
      },
      "source": [
        "model=Model(inputs=[cnn_input,bounding_box_input,animal_label_input],outputs=[orientation,path])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Tvep8ArPnD"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss={\n",
        "                  'orientation_output':CategoricalCrossentropy(from_logits=True),\n",
        "                  'path_output':MeanSquaredLogarithmicError()\n",
        "              })"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6AqS-GDyIi6"
      },
      "source": [
        "train_generator=AnimalDataGenerator(os.path.join(DATA_PATH,\"images\"),os.path.join(DATA_PATH,\"train.csv\"),BATCH_SIZE)\n",
        "test_generator=AnimalDataGenerator(os.path.join(DATA_PATH,\"images\"),os.path.join(DATA_PATH,\"test.csv\"),BATCH_SIZE)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDxHONbXyU0E",
        "outputId": "d34bd6af-f2a8-4b54-9afb-aa17685d737d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_generator.generate_image_batches(True),\n",
        "          epochs=3,\n",
        "          steps_per_epoch=train_generator.get_steps_per_epoch(),\n",
        "          validation_data=test_generator.generate_image_batches(True),\n",
        "          validation_steps=test_generator.get_steps_per_epoch())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "843/843 [==============================] - 662s 785ms/step - loss: 1.3515 - orientation_output_loss: 1.3157 - path_output_loss: 0.0359 - val_loss: 1.3246 - val_orientation_output_loss: 1.2942 - val_path_output_loss: 0.0304\n",
            "Epoch 2/3\n",
            "843/843 [==============================] - 180s 214ms/step - loss: 1.2701 - orientation_output_loss: 1.2420 - path_output_loss: 0.0281 - val_loss: 1.2758 - val_orientation_output_loss: 1.2427 - val_path_output_loss: 0.0331\n",
            "Epoch 3/3\n",
            "843/843 [==============================] - 189s 224ms/step - loss: 1.2317 - orientation_output_loss: 1.2045 - path_output_loss: 0.0272 - val_loss: 1.2637 - val_orientation_output_loss: 1.2333 - val_path_output_loss: 0.0304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb579d72470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhJ0m0e3thvj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}